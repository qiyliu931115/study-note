topic是逻辑上的概念，而partition是物理上的概念

每个partition都有一个log文件

producer生产的数据又不断追加到log文件末尾

为了防止log文件过大，Kafka通过分片和索引的方式

将每个partition分成了多个segment

每个segment下包含了.index文件 .log文件 .timeIndex 时间戳索引文件

Kafka默认保存7天的数据 .timeIndex文件就是判断日志保存多久的功能

![img_68.png](img_68.png)

index为稀疏索引 

大约每往log文件写入4kb数据，会往index文件写入一条索引

参数log.index.interval.bytes默认为4kb

index文件中保存的offset为相对offset

![img_69.png](img_69.png)

日志存储参数配置
---
log.segment.bytes

    Kafka 中 log 日志是分成一块块存储的，此配置是指 log 日志划分
    成块的大小，默认值 1G。

log.index.interval.bytes

    默认 4kb，kafka 里面每当写入了 4kb 大小的日志（.log），然后就
    往 index 文件里面记录一个索引。 稀疏索引。

文件清理策略
---

Kafka 中默认的日志保存时间为 7 天，可以通过调整如下参数修改保存时间

⚫ log.retention.hours，最低优先级小时，默认 7 天。

⚫ log.retention.minutes，分钟。 设置了这个小时的无效

⚫ log.retention.ms，最高优先级毫秒。 设置了这个分钟和小时的都无效

⚫ log.retention.check.interval.ms，负责设置检查周期，默认 5 分钟。


如果超过了日志的保存期限，Kafka提供了两种清理策略
---

1.delete删除 

    默认的清理策略就是删除

    log.cleanup.policy=delete

基于时间戳：以segment中记录的最大时间戳作为该文件的时间戳。最大的过期了，就会删除segment

基于大小：超过设置的所有日志总大小，删除最早的segment

![img_70.png](img_70.png)

2.compact压缩（相同key不同value，保存最后一个版本）

![img_71.png](img_71.png)

compact日志压缩：对于相同key的不同value值，只保留最后一个版本。

压缩后的offset可能是不连续的，比如上图中没有6，当从这些offset消费消息时，

将会拿到比这个offset大 的offset对应的消息，实际上会拿到offset为7的消息，

并从这个位置开始消费。

这种策略只适合特殊场景，比如消息的key是用户ID，value是用户的资料，

通过这种压缩策略，整个消息

集里就保存了所有用户最新的资料。