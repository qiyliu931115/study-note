传统定义
    
    发布订阅 消息队列 

最新定义

    流平台 做数据存储和计算

使用场景

    缓存削峰，解耦，异步通信

两种模式

    点对点 一个producer 一个consumer 一个topic 会删除数据

    发布订阅  多个producer 多个consumer 多个topic 不会删除数据

架构

    producer

        对接外部海量的数据

    broker 

        1.服务器
        2.topic 对数据分类
        3.partition 分区
        4.保证数据的可靠性 使用副本
        5.副本分为leader和follower，producer和consumer只对leader进行读写数据

    consumer

        1.consumer和consumer相互独立
        2.消费组 一个组只会消费某一个topic 一个topic的partition只能由一个consumer消费        

    zookeeper 

        1.不使用Kafka内部的zookeeper，使用外部公用的 结合Hadoop Hbase的zookeeper进行使用。
        2.存储brokerIds 
        3.每个topic下的每一个partition的leader


安装

    brokerId必须全局唯一
    配置文件修改brokerId, log.dirs存储位置默认temp目录，必须修改，连接对应的zookeeper
    启动，停止，要先停止Kafka，再停止zookeeper

    常用命令行
        kafka-topic.sh

        kafka-console-producer.sh

        kafka-console-consumer.sh

生产者producer

    kafkaProducer

    send方法

    拦截器

    序列化

    分区器

    缓存队列 默认32MB 每批次数据是16k
        
    sender线程发送数据 batch size和linger ms控制何时发送

    sender向broker发送请求会缓存五个请求，如果broker都没应答，就不会再发送请求

    sender里面使用的是selector处理IO流
    
    broker应答使用ack， 0-不用等 1-leader落盘应答 -1是leader和isr都落盘

    发送请求失败重试是integer.MAX

    发送方式

        send异步 send.get同步 send(.new callback())异步回调


分区

    分区可以把海量数据切割各服务器

    分区规则

        指定分区 

        指定key 按key的hashcode % 分区数

        没指定分区 也没指定key 粘性分区

        粘性分区 随机指定key 切换时随机

    自定义分区
    
        指定类 实现partitioner接口

        根据消息内容实现指定发送到哪个分区

    吞吐量如何提高

        batch size

        linger ms
        
        对消息压缩

        缓冲队列大小提高

    可靠性

        acks 
        0   丢失
        1   leader挂了 也可能丢失数据
        -1（all） 副本大于等于二，isr >=2 

    数据重复

        幂等性 默认开启，<pid（每次Kafka重启都会分配新的pid）,分区号，序列号>
            
        事务
            基于幂等性

            事务ID，手动设置 全局唯一

            事务协调器处理

    数据有序

        单会话单分区有序

        多分区有序 在consumer处理

    数据乱序
        
        未幂等性 inflight设置为1 broker
        
        开启幂等性 broker根据消息的序列号（单调递增的）对最多对五条数据进行缓冲并且重排序

        排序后在发送给consumer


        

    