### 传统算法

输入输出：结构化数据（数组/链表等）
确定性：绝对确定性（相同输入→相同输出）
调试方式：单元测试/边界用例
性能瓶颈：时间复杂度/内存访问
最优解证明：数学严谨证明


### 机器学习算法

输入输出：半结构化或结构化数据（特征向量、表格数据等）
确定性：部分确定性（同一训练集和随机种子下输出相同，不同训练过程有随机性）
调试方式：交叉验证/学习曲线/特征重要性分析
性能瓶颈：样本量/特征维度/计算资源
最优解证明：理论收敛性分析+测试集验证/泛化误差分析

### 深度学习算法

输入输出：非结构化数据（图像/文本）
确定性：概率性输出
调试方式：损失曲线/混淆矩阵
性能瓶颈：显存容量/浮点运算能力
最优解证明：经验性验证（测试集）

### 机器学习算法和深度学习算法的区别

| 方面           | 机器学习算法                   | 深度学习算法                  |
|----------------|-------------------------------|-------------------------------|
| **定义**       | 传统的统计学习方法，通过特征工程和模型训练实现预测与分类 | 基于多层神经网络的学习方法，自动学习复杂特征表示 |
| **特征工程**   | 依赖人工设计和选择特征         | 自动从数据中学习特征          |
| **模型复杂度** | 相对较低，如决策树、SVM、KNN等 | 模型非常复杂，如CNN、RNN、Transformer等 |
| **对数据量的需求** | 较小的数据集也可训练出不错模型 | 需要大量数据来发挥优势         |
| **计算资源**   | 资源消耗较低，普通电脑即可训练  | 需高性能GPU、大量内存和计算资源 |
| **可解释性**   | 通常可解释性较强               | 可解释性较差（黑盒模型）      |
| **应用场景**   | 小数据量、结构化数据、特征明显 | 大数据量、非结构化数据（如图像、语音、文本） |
| **举例**       | 逻辑回归、支持向量机、随机森林 | 卷积神经网络、循环神经网络、BERT |